{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "import numpy as  np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.FashionMNIST(root=\"data\",\n",
    "                                train=True,\n",
    "                                download=False,\n",
    "                                transform=transform)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset.data\n",
    "y_train = dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = datasets.FashionMNIST(root=\"data\",\n",
    "                                    train=False,\n",
    "                                    download=False,\n",
    "                                    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = val_dataset.data\n",
    "y_test = val_dataset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_index = dataset.class_to_idx\n",
    "class_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset=dataset,\n",
    "                              batch_size=32,\n",
    "                              shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=val_dataset,\n",
    "                             batch_size=32,\n",
    "                             shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_shape:int,\n",
    "                 output_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=64,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=128*5*5,\n",
    "                      out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=256,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.conv_block(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_model(input_shape=1,\n",
    "                  output_shape=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                             lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_fn(y_pred, y_true):\n",
    "    correct = torch.eq(y_pred, y_true).sum().item()\n",
    "    return (correct/len(y_pred))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(train_dataloader: DataLoader,\n",
    "               model: nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               loss_fn: nn.Module,\n",
    "               accuracy_fn,\n",
    "               devive: torch.device = \"cpu\"):\n",
    "    train_acc, train_loss = 0, 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model.train()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = model(X)\n",
    "        loss = loss_fn(y_hat, y)\n",
    "        acc = accuracy_fn(y_pred=y_hat.argmax(dim=1),\n",
    "                          y_true=y)\n",
    "        \n",
    "        train_loss += loss\n",
    "        train_acc += acc\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "    \n",
    "    train_loss /= len(train_dataloader)    \n",
    "    train_acc /= len(train_dataloader)\n",
    "    \n",
    "    print(f\"Train loss: {train_loss}    |    Train acc: {train_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(test_dataloader: DataLoader,\n",
    "              model: nn.Module,\n",
    "              loss_fn: nn.Module,\n",
    "              accuracy_fn,\n",
    "              device: torch.device = \"cpu\"):\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(test_dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = model(X)\n",
    "            loss = loss_fn(y_hat, y)\n",
    "            acc = accuracy_fn(y_pred=y_hat.argmax(dim=1),\n",
    "                              y_true=y)\n",
    "            test_loss += loss\n",
    "            test_acc += acc\n",
    "            \n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "        print(f\"Test loss: {test_loss}      |       Test acc: {test_acc}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [01:07<04:31, 67.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4210383892059326    |    Train acc: 84.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [02:04<03:03, 61.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27634063363075256    |    Train acc: 89.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [03:15<02:11, 65.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.23072242736816406    |    Train acc: 91.43833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [04:17<01:04, 64.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.19642680883407593    |    Train acc: 92.73833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:30<00:00, 66.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.16664279997348785    |    Train acc: 93.75833333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_step(train_dataloader=train_dataloader,\n",
    "               model=model,\n",
    "               optimizer=optimizer,\n",
    "               loss_fn=loss_fn,\n",
    "               accuracy_fn=accuracy_fn,\n",
    "               devive=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.25133606791496277      |       Test acc: 91.29392971246007\n"
     ]
    }
   ],
   "source": [
    "test_step(test_dataloader=test_dataloader,\n",
    "          model=model,\n",
    "          loss_fn=loss_fn,\n",
    "          accuracy_fn=accuracy_fn,\n",
    "          device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 128, 5, 5]           --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 26, 26]          640\n",
      "|    └─MaxPool2d: 2-2                    [-1, 64, 13, 13]          --\n",
      "|    └─ReLU: 2-3                         [-1, 64, 13, 13]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 128, 11, 11]         73,856\n",
      "|    └─MaxPool2d: 2-5                    [-1, 128, 5, 5]           --\n",
      "|    └─ReLU: 2-6                         [-1, 128, 5, 5]           --\n",
      "├─Sequential: 1-2                        [-1, 10]                  --\n",
      "|    └─Flatten: 2-7                      [-1, 3200]                --\n",
      "|    └─Linear: 2-8                       [-1, 256]                 819,456\n",
      "|    └─ReLU: 2-9                         [-1, 256]                 --\n",
      "|    └─Linear: 2-10                      [-1, 10]                  2,570\n",
      "==========================================================================================\n",
      "Total params: 896,522\n",
      "Trainable params: 896,522\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 11.03\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.45\n",
      "Params size (MB): 3.42\n",
      "Estimated Total Size (MB): 3.87\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Sequential: 1-1                        [-1, 128, 5, 5]           --\n",
       "|    └─Conv2d: 2-1                       [-1, 64, 26, 26]          640\n",
       "|    └─MaxPool2d: 2-2                    [-1, 64, 13, 13]          --\n",
       "|    └─ReLU: 2-3                         [-1, 64, 13, 13]          --\n",
       "|    └─Conv2d: 2-4                       [-1, 128, 11, 11]         73,856\n",
       "|    └─MaxPool2d: 2-5                    [-1, 128, 5, 5]           --\n",
       "|    └─ReLU: 2-6                         [-1, 128, 5, 5]           --\n",
       "├─Sequential: 1-2                        [-1, 10]                  --\n",
       "|    └─Flatten: 2-7                      [-1, 3200]                --\n",
       "|    └─Linear: 2-8                       [-1, 256]                 819,456\n",
       "|    └─ReLU: 2-9                         [-1, 256]                 --\n",
       "|    └─Linear: 2-10                      [-1, 10]                  2,570\n",
       "==========================================================================================\n",
       "Total params: 896,522\n",
       "Trainable params: 896,522\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 11.03\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.45\n",
       "Params size (MB): 3.42\n",
       "Estimated Total Size (MB): 3.87\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, torch.zeros(size=(1, 1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a sample\n",
    "random_idx = torch.randint(0, len(train_features_batch), size= [1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap= \"gray\")\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
